{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import LlavaForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = '/Users/jykim/Desktop/new/mlc-imp/dist/models/llava-1.5-7b-hf'\n",
    "\n",
    "image_file = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "prompt = \"USER: <image>\\nWhat are these?\\nASSISTANT:\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "raw_image = Image.open(requests.get(image_file, stream=True).raw)\n",
    "inputs = processor(prompt, raw_image, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3b26606eb84f0787c0e0ea63b1944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"LayerNormKernelImpl\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpixel_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[0;32m-> 1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[1;32m   1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:925\u001b[0m, in \u001b[0;36mCLIPVisionModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m>>> pooled_output = outputs.pooler_output  # pooled CLS states\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m    923\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[0;32m-> 1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[1;32m   1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:850\u001b[0m, in \u001b[0;36mCLIPVisionTransformer.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify pixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    849\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(pixel_values)\n\u001b[0;32m--> 850\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_layrnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    853\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    854\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    855\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    856\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    857\u001b[0m )\n\u001b[1;32m    859\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[0;32m-> 1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1502\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124;03m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    For state dicts without metadata, :attr:`local_metadata` is empty.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    Subclasses can achieve class-specific backward compatible loading using\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    the version number at `local_metadata.get(\"version\", None)`.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[1;32m   1511\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` is not the same object as the input\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03m        :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m        it can be modified.\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;124;03m        state_dict (dict): a dict containing parameters and\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;124;03m            persistent buffers.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m        prefix (str): the prefix for parameters and buffers used in this\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m        local_metadata (dict): a dict containing the metadata for this module.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;124;03m        strict (bool): whether to strictly enforce that the keys in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m            :attr:`state_dict` with :attr:`prefix` match the names of\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m            parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;124;03m        missing_keys (list of str): if ``strict=True``, add missing keys to\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;124;03m            this list\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;124;03m        unexpected_keys (list of str): if ``strict=True``, add unexpected\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m            keys to this list\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m        error_msgs (list of str): error messages should be added to this\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m            list, and will be reported together in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;124;03m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1535\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGroupNorm\u001b[39;00m(Module):\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies Group Normalization over a mini-batch of inputs as described in\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    the paper `Group Normalization <https://arxiv.org/abs/1803.08494>`__\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m        y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The input channels are separated into :attr:`num_groups` groups, each containing\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    ``num_channels / num_groups`` channels. :attr:`num_channels` must be divisible by\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    :attr:`num_groups`. The mean and standard-deviation are calculated\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    separately over the each group. :math:`\\gamma` and :math:`\\beta` are learnable\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    per-channel affine transform parameter vectors of size :attr:`num_channels` if\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    :attr:`affine` is ``True``.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    The standard-deviation is calculated via the biased estimator, equivalent to\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    `torch.var(input, unbiased=False)`.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    This layer uses statistics computed from input data in both training and\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    evaluation modes.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m        num_groups (int): number of groups to separate the channels into\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m        num_channels (int): number of channels expected in input\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m        eps: a value added to the denominator for numerical stability. Default: 1e-5\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m        affine: a boolean value that when set to ``True``, this module\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m            has learnable per-channel affine parameters initialized to ones (for weights)\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m            and zeros (for biases). Default: ``True``.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    Shape:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m        - Input: :math:`(N, C, *)` where :math:`C=\\text{num\\_channels}`\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m        - Output: :math:`(N, C, *)` (same shape as input)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Examples::\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m        >>> input = torch.randn(20, 6, 10, 10)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        >>> # Separate 6 channels into 3 groups\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m        >>> m = nn.GroupNorm(3, 6)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m        >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m        >>> m = nn.GroupNorm(6, 6)\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m        >>> # Put all 6 channels into a single group (equivalent with LayerNorm)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m        >>> m = nn.GroupNorm(1, 6)\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        >>> # Activating the module\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m        >>> output = m(input)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     __constants__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_groups\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_channels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maffine\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    242\u001b[0m     num_groups: \u001b[38;5;28mint\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/nn/functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2540\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   2542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 3D or higher dimensionality \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;124m                     input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2545\u001b[0m             dim\n\u001b[0;32m-> 2546\u001b[0m         )\n\u001b[1;32m   2547\u001b[0m     )\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"LayerNormKernelImpl\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "model.vision_tower(inputs['pixel_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_encoder = model.vision_tower.vision_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(clip_encoder, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._export'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exported_mod \u001b[38;5;241m=\u001b[39m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m577\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-env/lib/python3.8/site-packages/torch/export/__init__.py:450\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(f, args, kwargs, constraints, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._export'"
     ]
    }
   ],
   "source": [
    "exported_mod = export(clip_encoder, torch.randn(1, 577, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
